{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43254d66",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# データサイエンス応用 #2\n",
    "\n",
    "今回から、早速、テキストマイニングを実践したいと思います。\n",
    "自然言語処理の活用事例には、「検索エンジン」「機械翻訳」「文章要約」「対話型AI、チャットボット」「音声認識、AIスピーカー」等、ここには書ききれないほどあります。\n",
    "今回からしばらくは、簡単な分析の例として、青空文庫（ https://www.aozora.gr.jp/ ）の小説を対象として、作品や著者によって異なる文章の特徴を調べていきたいと思います。\n",
    "\n",
    "# 「文字」「文」「単語」の処理\n",
    "\n",
    "テキストを処理するとき、多くの場合、「文字」「文」「単語」の単位で処理をすることになります。\n",
    "\n",
    "例えば、\n",
    "\n",
    "---\n",
    "\n",
    "    私は西村です。\n",
    "    こんにちは。元気ですか？\n",
    "\n",
    "---\n",
    "\n",
    "というテキストを処理することを考えましょう。\n",
    "\n",
    "文字単位の処理では、「`私`」「`は`」「`西`」「`村`」「`で`」「`す`」「`。`」のように、一文字ごとに処理をすることになります。\n",
    "他言語やアルファベットでも同様です。\n",
    "\n",
    "文単位だと少し話はややこしくなります。\n",
    "「文」の定義を決めないといけません。\n",
    "日本語の場合、「文」は、「`。`(句点)」から「`。`(句点)」までのまとまった内容を表すひと続きになると思います。\n",
    "\n",
    "一方で、改行で区切ることを文の定義とした場合、 上記の例は、「`私は西村です。`」と「`こんにちは。元気ですか？`」の二つの文となります。\n",
    "日本語の場合、これは本来の「文」の定義ではありませんが、コンピュータを使った処理では、簡単な「文」のようなものとして扱われることもあります。\n",
    "\n",
    "ただし、日本語の場合は、`。`（句点）を文の区切りとするのが基本です。\n",
    "` 。`で区切った場合、上記の例は、「`私は西村です。`」「`こんにちは。`」「`元気ですか？`」と３つの文となります。\n",
    "`。`だけではなく、`？`や`！`で区切る必要がある場合もあります。\n",
    "\n",
    "また、\n",
    "\n",
    "---\n",
    "\n",
    "    私は、「こんにちは。」と言った。\n",
    "\n",
    "---\n",
    "では、`。`で単純に区切ることはできず、この場合は、一つの文として扱うことが通常となります。\n",
    "このように「文」というものを扱うだけでもなかなか難しい話になります。\n",
    "\n",
    "さらにややこしいのが「単語」を単位とする場合です。\n",
    "英語の場合、基本的には、単語は空白で区切られています。\n",
    "このため、厳密でなければ、空白を目印とすることで、簡単な手順で単語単位の処理が可能です。\n",
    "一方、日本語では、単語は空白で区切られておらず、単語を区切るという作業は、そもそも人間であっても難しく、人によって結果に違いがでてきます。\n",
    "例えば、「`和歌山大学`」は、「`和歌山`」と「`大学`」に区切ることができますし、「`和歌山大学`」という一つの固有名詞として扱うこともできます。\n",
    "\n",
    "この授業では、「言語」の深い部分まで議論することはできません。\n",
    "単語を区切る（わかち書き）に関する研究の成果として「形態素解析」というものがあります。\n",
    "「形態素」とは、言語学の用語で「意味をもつ表現要素の最小単位」のことで、日本語の場合は、ほとんど「単語」と同じだと考えることができます。 「形態素解析」は、自然言語処理研究の分野において、もっとも基本であり、かつ、常に発展している研究テーマとなっています。\n",
    "本授業では、その成果を利用させていただき、既存の形態素解析プログラムが出力した結果を利用した単語単位の処理を行います。\n",
    "\n",
    "前置きが長くなりましたが、「文字」を単位とする処理からはじめてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80fec0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 文字単位の処理\n",
    "\n",
    "## 文字の出現回数\n",
    "\n",
    "それでは、次のコードを実行してみてください。\n",
    "このプログラムは、文字列（`s`）に含まれる文字の登場回数を求めるものです。\n",
    "対象の文字列は、英字でも、日本語でも動作します。\n",
    "\n",
    "文字数を数えるには、Python標準の`collection`モジュールの`Counter`クラスを使うことができます。\n",
    "戻り値は、辞書型で`{文字: 出現回数}`のようになります。\n",
    "\n",
    "---\n",
    "    from collections import Counter\n",
    "\n",
    "    s = \"This is a pen.\"\n",
    "    c = Counter(s)\n",
    "    print(s)\n",
    "    print(c)\n",
    "    print()\n",
    "\n",
    "    s = \"吾輩は猫である。名前はまだ無い。\"\n",
    "    c = Counter(s)\n",
    "    print(s)\n",
    "    print(c)\n",
    "    \n",
    " ---\n",
    " \n",
    "キーとして要素を指定するとその個数を取得することができます。要素として存在しない値を指定すると0を返します。\n",
    "例えば、以下のようになります。\n",
    "\n",
    "---\n",
    "\n",
    "    print(c['猫'])\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52cdb11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "722efae5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`Counter`は`most_common()`で出現回数順に並べたリストを取得することができます。\n",
    "次のプログラムのように、`c.most_common(20)`とすると上位20個を取得することができます。\n",
    "\n",
    "出現回数が最も多いものは`[0]`、最も少ないものは`[-1]`で取得できます。\n",
    "\n",
    "出現回数の少ない順に並べ替えたい場合は、増分を-1として、`print(c.most_common()[::-1])`とすることができます。\n",
    "\n",
    "なお、このプログラムでは、入力ファイルとして`plain.txt`を使用しています。\n",
    "これには、前回の課題解説で作成した「吾輩は猫である」のプレーンテキストを使用してください（ファイル名は`plain.txt`にしています）。\n",
    "\n",
    "コードの中では、`values, counts = zip(*c.most_common(top))`で、`values（文字）`と`counts（回数）`に分解しています。\n",
    "そして、その値をもとに`matplotlib`の`plt.bar()`で棒グラフをプロットしています。\n",
    "\n",
    "`matplotlib`の`xlabel`や`ylabel`で漢字ひらがなを使う際には、フォントの設定が必要です。\n",
    "ここでは、Windows環境を想定したフォントの設定をしています。\n",
    "\n",
    " ---\n",
    "    %matplotlib inline\n",
    "    from collections import Counter\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # matplotlibのフォントの設定\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "    path = \"./plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    top = 20  # 出力する上位数\n",
    "    c = Counter(s)\n",
    "    print(c.most_common(top)) # most_comon()で上位を抽出\n",
    "\n",
    "    values, counts = zip(*c.most_common(top))\n",
    "    plt.bar(values, counts)\n",
    "    plt.xlabel(\"上位\" + str(top) )\n",
    "    plt.ylabel(\"出現回数\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7291dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d58c7251",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#  文単位の処理\n",
    "## 改行で区切る場合\n",
    "\n",
    "次に文単位で処理する例を見てみましょう。\n",
    "\n",
    "次のコードは`readlines()`で読み込んだ各行を文としてみなし、 各行（各文） に含まれる文字数`len(x)`を取得するプログラムです。\n",
    "`[len(x) for x in lines]`は、Pythonのリスト内包表記で`lines`の各行`x`に長さ`len(x)`のリストを取得することができます。\n",
    "\n",
    "---\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "    cnt = Counter([len(x) for x in lines])\n",
    "    print(cnt.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afcec6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dfc4c35",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ところで、このプログラムを実行すると、トップが`(1, 86)`であり、1文字で構成された文（行）がもっとも多いことがわかります。\n",
    "これはなぜでしょうか？\n",
    "次のプログラムをつかって1文字だけの行を表示してみましょう。\n",
    "\n",
    "なお、このプログラムでは、`print(repr(x))`の`repr()`によって、各行`x`を`print()`する際にraw文字列に変換してから出力しています。\n",
    "\n",
    "---\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "    for x in lines:\n",
    "            if len(x) == 1:\n",
    "                    # raw文字列に変換してからprint()\n",
    "                    print(repr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5277d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9cc8dc6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "予想できた人も多いと思いますが、1文字だけの行は、\n",
    "\n",
    "    '\\n'\n",
    "\n",
    "であり、改行のみの行、つまり空行であることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52864062",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "空行のみの行を削除する方法は、いくつもの方法がありますが、今回は、次の方法をご紹介したいと思います。\n",
    "\n",
    "---\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    # 文字列を改行ごとに分割し、リスト化\n",
    "    lines = s.splitlines()\n",
    "\n",
    "    # 空行を削除\n",
    "    while '' in lines:\n",
    "            lines.remove('')\n",
    "    \n",
    "    # 結果をraw文字にして出力\n",
    "    for l in lines:\n",
    "            print(repr(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4a6016",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb05aef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "このコードでは、文章（ファイル）全体を\n",
    "\n",
    "    s = f.read()\n",
    "\n",
    "で一つの文字列`s`に代入しています。 その後、\n",
    "\n",
    "    lines = s.splitlines()\n",
    "\n",
    "によって、全体`s`を各行で分割して、リスト`lines`にしています。\n",
    "文字列に対するメソッド`splitlines()`では、文字列を改行ごとに分割し、リスト化することができます。\n",
    "このとき、各行の末尾には改行文字は含まれません。\n",
    "\n",
    "実際に空行のみの行を削除しているのは、\n",
    "\n",
    "     while '' in lines:\n",
    "            lines.remove('')\n",
    "\n",
    "の部分です。\n",
    "`remove()`は、リストに対するメソッドで、指定した値と同じ要素を検索し、最初の要素を削除するものです。\n",
    "つまり、\n",
    "    lines.remove('')\n",
    "によって、`lines`の中から、空行（''）の最初のものを削除します。\n",
    "ただし、2番目以降は残りますから、`while`で`lines`の中に空行（''）が存在する限り、繰り返しをしています。\n",
    "\n",
    "空行のみを削除する方法は、ほかにもさまざまな方法が考えられますので、考えてみましょう。\n",
    "\n",
    "次のプログラムは、空行を削除した上で、文字数200未満の行のみ文字数`len()`を取得、各行を構成する文字数のヒストグラムを出力するものです。プログラムを順に読んでみてください。\n",
    "\n",
    "---\n",
    "\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # matplotlibのフォントの設定\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    # 文字列を改行ごとに分割し、リスト化\n",
    "    lines = s.splitlines()\n",
    "\n",
    "    # 空行を削除\n",
    "    while '' in lines:\n",
    "            lines.remove('')\n",
    "\n",
    "    # 文字数200未満の行のみ文字数len()を取得\n",
    "    cnt = np.array([len(x) for x in lines if len(x) < 200])\n",
    "\n",
    "    # ヒストグラムの生成\n",
    "    # bins, 表示する棒の数（ビン数）defulat:10\n",
    "    plt.hist(cnt, bins=cnt.max())\n",
    "    plt.xlabel(\"文字数（文単位）\")\n",
    "    plt.ylabel(\"出現頻度\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec009c18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "173aa99c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 句点（。）で区切る場合\n",
    "\n",
    "さて、ここまでは改行（`\\n`）を一つの文の区切りとみなしていましたが、`plain.txt`の中にも、\n",
    "\n",
    "    どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。掌の上で少し落ちついて書生の顔を見たのがいわゆる人間というものの見始であろう。この時妙なものだと思った感じが今でも残っている。第一毛をもって装飾されべきはずの顔がつるつるしてまるで薬缶だ。その後猫にもだいぶ逢ったがこんな片輪には一度も出会わした事がない。のみならず顔の真中があまりに突起している。そうしてその穴の中から時々ぷうぷうと煙を吹く。どうも咽せぽくて実に弱った。これが人間の飲む煙草というものである事はようやくこの頃知った。\n",
    "\n",
    "が一行になっている部分があったりと、それではあまり意味がないことがわかります。\n",
    "ここからは、文を句点（`。`）で区切られたものとして処理する方法を考えてみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c855b50",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次のコードを見てください。\n",
    "`splitlines()`ではなく、正規表現を使った`re.split()`によって、全体の文字列`s`を分割しています。\n",
    "\n",
    "正規表現のパターンは、`。|\\n`としています。\n",
    "これによって`s`は、句点（`。`）もしくは、改行（`\\n`）によって分割されます。\n",
    "\n",
    "---\n",
    "    import re\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    # 文字列を分割し、リスト化\n",
    "    lines = re.split(\"。|\\n\", s)\n",
    "    #lines = re.split(\"。(?!」)|\\n\", s)\n",
    "\n",
    "    # 空行を削除\n",
    "    while '' in lines:\n",
    "            lines.remove('')\n",
    "\n",
    "    for l in lines:\n",
    "            print(repr(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f612ac8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1dd9d573",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ただし、このままだと、例えば、\n",
    "\n",
    "---\n",
    "\n",
    "    「元気です。」と、私は言った。\n",
    "\n",
    "---\n",
    "\n",
    "が、\n",
    "\n",
    "---\n",
    "\n",
    "    「元気です\n",
    "    」と、私は言った\n",
    "\n",
    "---\n",
    "\n",
    "のように分割されてしまいます。\n",
    "これを防ぐには、`」`の直前の句点（`。`）では、区切らないほうが良いようです。\n",
    "\n",
    "正規表現のパターンを\n",
    "\n",
    "    。(?!」)|\\n\n",
    "\n",
    "に変更してみましょう。\n",
    "\n",
    "Pythonの正規表現モジュール`re`では、`(?!...)`は、`...`が次に続くものにマッチしなければマッチするというルールになっています。\n",
    "つまり、`(?!」)`は、`」`が後ろに続かなければマッチするという意味になります。\n",
    "その結果、`。(?!」)`は、`。`のあとに`」`がなければマッチします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d941c6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "先ほどのプログラムの正規表現パターンを変更して（コメントで無効になっている部分を有効にして）、再度実行してみると、上記の例は、修正されます。\n",
    "ただし、どうやら、`plain.txt`の元になった`wagahaiwa_nekodearu.txt`では、登場人物の発言を示す`「」`の中の文章末には、`。`は使われておらず、この変更は、残念ながらあまり意味をなしません。\n",
    "\n",
    "また、\n",
    "\n",
    "---\n",
    "\n",
    "    「もうよそう。勝手にするがいい。がりがりはこれぎりご免蒙るよ」と、前足も、後足も、頭も尾も自然の力に任せて抵抗しない事にした。\n",
    "\n",
    "---\n",
    "は、\n",
    "\n",
    "---\n",
    "\n",
    "    「もうよそう\n",
    "     勝手にするがいい\n",
    "     がりがりはこれぎりご免蒙るよ」と、前足も、後足も、頭も尾も自然の力に任せて抵抗しない事にした\n",
    "\n",
    "---\n",
    "\n",
    "のように区切られてしまう問題が残っています。\n",
    "文章を区切るというのはなかなか奥の深い、沼のような処理が必要になることがわかっていただけるでしょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce1bb3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次のプログラムは、句点（`。`）で区切った各文のうち、200文字未満を抽出し、その文字数のヒストグラムを出力するプログラムです。出力結果を確認してください。\n",
    "\n",
    "---\n",
    "\n",
    "    %matplotlib inline\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "\n",
    "    # matplotlibのフォントの設定\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    # 文字列を分割し、リスト化\n",
    "    lines = re.split(\"。(?!」)|\\n\", s)\n",
    "\n",
    "    # 空行を削除\n",
    "    while '' in lines:\n",
    "            lines.remove('')\n",
    "\n",
    "    # 文字数200未満の行のみ文字数len()を取得\n",
    "    cnt = np.array([len(x) for x in lines if len(x) < 200])\n",
    "\n",
    "    # ヒストグラムの生成\n",
    "    # bins, 表示する棒の数（ビン数）defulat:10\n",
    "    plt.hist(cnt, bins=cnt.max())\n",
    "    plt.xlabel(\"文字数（文単位）\")\n",
    "    plt.ylabel(\"出現頻度\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff5046",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26e99f76",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 単語単位の処理\n",
    "## Janomeのインストール\n",
    "\n",
    "ここからは形態素解析を使った単語単位の処理の話をします。\n",
    "\n",
    "日本語のテキストで単語単位の処理を行うためには、形態素解析によってテキストを単語に分割する必要があります。\n",
    "形態素解析には、高度な処理が必要であり、多くの研究がこれまでなされていますが、現在では、オープンソースで公開されているプログラムを利用することができます。\n",
    "有名なものにMeCab（ https://taku910.github.io/mecab/ ）があります。 \n",
    "MecabをPythonで利用することも可能で、実際にMecabが利用されることが多いです。\n",
    "しかし、もともとMeCabはPython用のソフトウェアではなく、また、Windowsにインストールするのが少しだけ面倒です（といっても、次回以降にインストールする予定です）。\n",
    "\n",
    "今回は、インストールが簡単で、Pythonで実装された、Python用の形態素解析器であるJanome（ https://mocobeta.github.io/janome/ ）を利用したいと思います。\n",
    "Janomeは、MeCabの辞書データを利用しており、MeCabと同等の解析結果を出力することが可能です。\n",
    "また、依存ライブラリなしで簡単にインストールでき、Pythonのアプリケーションに組み込みやすいシンプルなAPIが提供されています。\n",
    "ただし、MeCabに比べると処理速度が遅いことが欠点であり、大量のテキストデータを処理したいときなどは、MeCabの導入した方がよいでしょう。\n",
    "\n",
    "形態素解析のプログラムには、JanomeやMeCab以外にも多くのものがあります。\n",
    "また、Web API経由で利用することができるようにしたウェブサービスなども提供されています。\n",
    "皆さんの目的にあったものを選ぶようにしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5414b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "それでは、Janomeをインストールしてみましょう。\n",
    "Janomeは、Anacondaには含まれていないので追加のインストールが必要です。\n",
    "といっても、Pythonのライブラリとして公開されているため、他のモジュールと同様に簡単にインストールすることができます。\n",
    "Pythonで追加ライブラリをインストールには、Pythonの外部コマンドである`pip`コマンドを利用します。\n",
    "Jupyter Notebookで外部コマンドを実行するときには、以下のように、`!`を付けて実行してください。\n",
    "\n",
    "---\n",
    "\n",
    "    !pip install janome\n",
    "\n",
    "---\n",
    "`Successfully installed janome-0.4.2`といった感じに表示されたらインストールは完了です。\n",
    "\n",
    "もしかしたら、インストールしたモジュールを反映させるために、Jupyter Notebook（のkernel）をrestartさせる必要があるかもしれません。その際は、`pip`でインストールした後、Jupyter Notebookの上部メニューの「`Kernel`」→「`Restart`」を試してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0f77a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c2e549",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "PythonプログラムからJanomeをつかってみましょう。\n",
    "次のコードを実行してください。\n",
    "\n",
    "---\n",
    "\n",
    "    from janome.tokenizer import Tokenizer\n",
    "\n",
    "    t = Tokenizer()\n",
    "\n",
    "    input_txt = \"主人公「吾輩」のモデルは、夏目漱石に家に迷い込んで住み着いた野良の黒猫である。猫が死亡した際、漱石は親しい人達に猫の死亡通知を出した。\"\n",
    "    #input_txt = \"すもももももももものうち\"\n",
    "\n",
    "    for token in t.tokenize(input_txt):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43882e31",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4982d9f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Janomeの出力では、単語単位に区切られた結果が出力されます。\n",
    "\n",
    "区切られた（わかち書きされた）単語そのものである表層形（surface）の他に、\n",
    "- 品詞（`part_of_speech`）\n",
    "- 活用型（`infl_type`）\n",
    "- 活用形（`infl_form`）\n",
    "- 基本形・見出し語（`base_form`）\n",
    "- 読み（`reading`）\n",
    "- 発音（`phonetic`）\n",
    "の情報が含まれます。\n",
    "\n",
    "該当する情報が存在しないときは、`*`が表示されます。\n",
    "また、品詞（`part_of_speech`）には、「`品詞,品詞細分類1,品詞細分類2,品詞細分類3`」といったように、詳細な品詞情報が付与されています（細分類がないときは`*`になります）。\n",
    "\n",
    "「主人公」の読み（reading）は「シュジンコウ」なのに対して、発音（phonetic）が「シュジンコー」になっていることにも注目してください。\n",
    "\n",
    "また、「すもももももももものうち」も正しく解析できます。\n",
    "\n",
    "使い方を説明します。\n",
    "\n",
    "入力文字列`input_txt`に対して、形態素解析の結果が取得できています。\n",
    "\n",
    "    t = Tokenizer()\n",
    "    \n",
    "で`Tokenizer`オブジェクトを作り（初期化）、`tokenize()`メソッドに解析したい文字列を渡しています。\n",
    "\n",
    "戻り値は`Token`オブジェクトのイテレータです。\n",
    "イテレータ（複数の要素を持っており、順番にデータを取り出すことができるもの）なので、`for`ループなどで要素を取り出す必要があります。\n",
    "つまり、\n",
    "\n",
    "    for token in t.tokenize(input_txt):\n",
    "        print(token)\n",
    "\n",
    "の`token`として取得することができます。\n",
    "\n",
    "今後、解析を連続して実行することがありますが、`t = Tokenizer()`の初期化は、遅い処理になるので、何度も実行しないようにしてください。\n",
    "例えば、`for`や`while`でループをまわすときは、ループの外に記述する必要があります（基本的にはプログラムの最初の方で一回記述すればOKです）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62894384",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次に、表層形（つまり、単語）のみを出力する「わかち書きモード」を試してみます。\n",
    "\n",
    "`tokenize()`メソッドに`wakati = True`オプションを追加します。\n",
    "\n",
    "---\n",
    "\n",
    "    from janome.tokenizer import Tokenizer\n",
    "\n",
    "    t = Tokenizer()\n",
    "\n",
    "    input_txt = \"主人公「吾輩」のモデルは、夏目漱石に家に迷い込んで住み着いた野良の黒猫である。猫が死亡した際、漱石は親しい人達に猫の死亡通知を出した。\"\n",
    "\n",
    "    # わかち書きモード（表層形のみを返すモード）\n",
    "    for token in t.tokenize(input_txt, wakati=True):\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0ec35",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5f9724e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次のコードでは`token`から、表層形（`surface`）、品詞（`part_of_speech`）、活用型（`infl_type`）、活用形（`infl_form`）、基本形・見出し語（`base_form`）、読み（`reading`）、発音（`phonetic`）の情報をそれぞれ取得しています。\n",
    "\n",
    "---\n",
    "\n",
    "    from janome.tokenizer import Tokenizer\n",
    "\n",
    "    t = Tokenizer()\n",
    "\n",
    "    input_txt = \"主人公「吾輩」のモデルは、夏目漱石に家に迷い込んで住み着いた野良の黒猫である。猫が死亡した際、漱石は親しい人達に猫の死亡通知を出した。\"\n",
    "\n",
    "    for token in t.tokenize(input_txt):\n",
    "        print(\"--\")\n",
    "        print(\"表層系: \" + token.surface)\n",
    "        print(\"品詞: \" + token.part_of_speech)\n",
    "        print(\"活用型: \" + token.infl_type)\n",
    "        print(\"活用形: \" + token.infl_form)\n",
    "        print(\"基本形: \" + token.base_form)\n",
    "        print(\"読み: \" + token.reading)\n",
    "        print(\"発音: \" + token.phonetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a8608",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b6a7e8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "ファイルから読み込んだ文字列を形態素解析する実装の例を示します。\n",
    "\n",
    "---\n",
    "\n",
    "    from janome.tokenizer import Tokenizer\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    t = Tokenizer()\n",
    "    for token in t.tokenize(s):\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6e833",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab50309b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 単語の出現頻度\n",
    "\n",
    "Janomeをつかって形態素解析をして、単語ごとの出現回数の棒グラフをプロットするプログラムです。わかち書きモードの結果を利用しています。\n",
    "例では、上位100単語を出力していますが`top`の値を調整してください。\n",
    "\n",
    "助詞や句読点等の記号が多いようです。\n",
    "それらは除外した方が、文章の特徴がわかりやすくなるかもしれません。\n",
    "\n",
    "---\n",
    "    %matplotlib inline\n",
    "    import numpy as np\n",
    "    from collections import Counter\n",
    "    from janome.tokenizer import Tokenizer\n",
    "    import matplotlib.pyplot as plt\n",
    "    # matplotlibのフォントの設定\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "            s = f.read()\n",
    "\n",
    "    t = Tokenizer()\n",
    "\n",
    "    c = Counter(t.tokenize(s, wakati=True))\n",
    "\n",
    "    top = 100  # 出力する上位数\n",
    "    print(c.most_common(top))\n",
    "\n",
    "    values, counts = zip(*c.most_common(top))\n",
    "    plt.bar(values, counts)\n",
    "    plt.xlabel(\"上位\" + str(top) )\n",
    "    plt.ylabel(\"出現回数\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5a3cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23d7f0ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "最後に、文ごとに構成する単語数のヒストグラムをプロットしてみましょう。\n",
    "これもこれまで解説してきたことに、形態素解析の結果を入力したものになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab8209",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "なお、このプログラムでは、\n",
    "\n",
    "    [word_count(x) for x in lines]\n",
    "    \n",
    "の部分で、文（`x`）ごとに形態素解析をする必要があるため、新しい関数`word_count()`を先に定義します。\n",
    "`word_count()`の戻り値は、形態素解析後の単語の数`len(w)`です。\n",
    "\n",
    "---\n",
    "    # 関数の定義\n",
    "    def word_count(l):\n",
    "            w = [token for token in t.tokenize(l, wakati=True)]\n",
    "            #print(w)\n",
    "\n",
    "            return len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a9704e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1fee2f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`word_count()`関数が定義できたら、次のプログラム本体を実行してください。\n",
    "なお、 文の分割には、\n",
    "\n",
    "    lines = re.split(\"。(?!」)|\\n\", s)\n",
    "\n",
    "を利用しています。\n",
    "\n",
    "---\n",
    "\n",
    "    %matplotlib inline\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from janome.tokenizer import Tokenizer\n",
    "    # matplotlibのフォントの設定\n",
    "    from matplotlib import rcParams\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "    path = \"plain.txt\"\n",
    "\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        s = f.read()\n",
    "\n",
    "    # 文字列を分割し、リスト化（文単位）\n",
    "    lines = re.split(\"。(?!」)|\\n\", s)\n",
    "\n",
    "    # 空行を削除\n",
    "    while '' in lines:\n",
    "        lines.remove('')\n",
    "\n",
    "    # Tokenizer()のインスタンス生成はループの外で実行\n",
    "    # とても遅いため\n",
    "    t = Tokenizer()\n",
    "\n",
    "    cnt = np.array([word_count(x) for x in lines])\n",
    "\n",
    "    # ヒストグラムの生成\n",
    "    # bins, 表示する棒の数（ビン数）defulat:10\n",
    "    plt.hist(cnt, bins=cnt.max())\n",
    "    plt.xlabel(\"単語数（文単位）\")\n",
    "    plt.ylabel(\"出現頻度\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca41ee1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de508641",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "今回の授業は以上となります。\n",
    "Janomeには、まだまだ他にも機能があります。\n",
    "形態素解析の前処理・後処理するためのフレームワーク`Analyzer`は便利です。\n",
    "文字の正規化などの前処理、小文字化、品詞によるトークンのフィルタリングなどの形態素解析後の後処理は、実社会に存在しているテキストを処理する上で必要となります。\n",
    "\n",
    "また、Janomeは、MeCabの標準辞書（IPADIC）を内包しています。\n",
    "ただし、IPADICには、最近の新しい単語などは登録されておらず、ウェブのテキスト等を解析すると高い精度を得ることができません。\n",
    "このため、ユーザ定義辞書を使ったり、新しい辞書を使う必要があります。\n",
    "Janomeでは、ユーザ定義辞書を使ってIPADICに単語を追加することができます。\n",
    "\n",
    "新しい単語も含んだ「NEologd（ねおろぐでぃー）辞書（mecab-ipadic-NEologd）」（ https://github.com/neologd/mecab-ipadic-neologd/blob/master/README.ja.md ）という辞書を利用することもできます。\n",
    "この辞書は、ウェブ上の多数の言語資源から得た新語を追加することでカスタマイズしたMeCab用辞書です。\n",
    "頻繁に更新されており、新語・固有表現に強く、語彙数が多く、オープンソースであるという特徴があります。\n",
    "\n",
    "Janomeのウェブサイト（ https://mocobeta.github.io/janome/ ）には、NEologd辞書をJanomeで利用する方法の説明があります。\n",
    "興味がある人は、試してみるとよいでしょう （メモリ使用量が多くなり、処理が重くなりますので、この授業ではとりあえず使わないようにします）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527022a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 本日の課題\n",
    "\n",
    "## 課題1\n",
    "\n",
    "句点（`。`）に基づいて、文に分割するプログラムを完成させなさい。\n",
    "ただし、「」の中の。は区切らず、一つの繋がった文として出力するようにすること。\n",
    "\n",
    "この課題は、Pythonの有用なライブラリを活用することを目的とします。\n",
    "これまで述べたように、Pythonにはさまざまな有用なライブラリがあり、それを`pip`でインストールすることで利用できます。\n",
    "使えそうなライブラリを探して、`pip`でインストールして使用してください。 使用することができるライブラリは、`!pip install`で自動的にダウンロードしてインストールできるものに限ります。\n",
    "\n",
    "ヒント：\n",
    "`plain.txt`（`wagahaiwa_nekodearu.txt`）を入力としたとき、完成したプログラムで保存した出力のサンプル（`wagahaiwa_nekodearu.sentence.txt`）をMoodleコースに添付します。\n",
    "これと同様の出力ができればOKです。\n",
    "\n",
    "ファイルのほぼ終盤で、\n",
    "\n",
    "    「もうよそう。勝手にするがいい。がりがりはこれぎりご免蒙るよ」と、前足も、後足も、頭も尾も自然の力に任せて抵抗しない事にした。\n",
    "\n",
    "が一つの文として出力できていることがわかると思います。\n",
    "\n",
    "適切なライブラリをみつけることができれば、難しいプログラムではありません。\n",
    "ライブラリを使わないと、とても大変なプログラムとなりますが、修行として実装に挑戦してもらってもOKです（とりあえず私はやろうとは思っていません）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75273537",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "まず、以下のセルをつかって `!pip install hogehogehoge`で探したライブラリをインストールしてください。`hogehogehoge`の部分はライブラリの名前が入ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79428343",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "392d00d3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "次のセルには、コードを入力して、文を分割した結果を`wagahaiwa_nekodearu.sentence.txt`に保存するようにしてください。なお、セルには、ヒントを記載しているので、不足部分を補うことでコードを完成させることができます（ヒントを使わずゼロから記述しても構わない）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb567c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "### この部分にコードを追加する\n",
    "\n",
    "path = \"plain.txt\"\n",
    "\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "        s = f.read()\n",
    "\n",
    "### この部分にコードを追加する\n",
    "\n",
    "### 分割後の各行をprint()\n",
    "for l in lines:\n",
    "        print(l)\n",
    "\n",
    "### 分割後の各行を\\nで結合してからファイルに書き出し\n",
    "output_file = \"wagahaiwa_nekodearu.sentence.txt\"\n",
    "with open(output_file, mode='w', encoding=\"utf_8\") as f:\n",
    "    f.write('\\n'.join(lines))\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceee379",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 課題2\n",
    "\n",
    "`plain.txt`（`wagahaiwa_nekodearu.txt`）を形態素解析した結果から、名詞のみを抽出し、その上位20単語の出現回数を棒グラフでプロットするプログラムを実装しなさい。 ただし、「名詞,非自立」は除外すること。\n",
    "\n",
    "ヒント：\n",
    "出力したグラフの例をMoodleに掲載します。\n",
    "そのグラフと同様なものが出力できればOKです。\n",
    "なお、セルには、ヒントを記載しているので、不足部分を補うことでコードを完成させることができます（ヒントを使わずゼロから記述しても構わない）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fbf79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from janome.tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlibのフォントの設定\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meirio', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']\n",
    "\n",
    "path = \"plain.txt\"\n",
    "\n",
    "with open(path, encoding=\"utf-8\") as f:\n",
    "        s = f.read()\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "### この部分にコードを追加する\n",
    "\n",
    "\n",
    "\n",
    "top = 20  # 出力する上位数\n",
    "print(c.most_common(top))\n",
    "\n",
    "values, counts = zip(*c.most_common(top))\n",
    "plt.bar(values, counts)\n",
    "plt.xlabel(\"上位\" + str(top) )\n",
    "plt.ylabel(\"出現回数\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7919dc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 提出方法\n",
    "上記のコードを参考にして、セルに課題の回答となる外部コマンドとコードを入力して実行してください。\n",
    "実行できたら、Notebook形式ファイル（.ipynb）を保存（File -> Download as）して、保存した.ipynbのファイルをMoodleコースから提出してください（次回課題の解説をしますから、あきらめずに提出してください）。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}